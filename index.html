<html lang="en-GB">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CochStream: Additional Visualizations</title>
    <meta name="description" content="We've presented Clarity, a minimalist and elegant website template for AI research.">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <meta name="robots" content="all">
    <meta content="en_EN" property="og:locale">
    <meta content="website" property="og:type">
    <meta content="https://shikun.io/projects/clarity" property="og:url">
    <meta content="Clarity" property="og:title">
    <meta content="Website Template for AI Research" property="og:description">

    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@your_twitter_id">
    <meta name="twitter:description" content="Clarity: A Minimalist Website Template for AI Research">
    <meta name="twitter:image:src" content="assets/figures/logo.png">
    
    <link rel="stylesheet" type="text/css" media="all" href="assets/stylesheets/main_free.css" />
    <link rel="stylesheet" type="text/css" media="all" href="clarity/clarity.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/foundation.min.css">
    <link href="assets/fontawesome-free-6.6.0-web/css/all.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/img-comparison-slider@8/dist/styles.css"/>
    <script defer src="https://cdn.jsdelivr.net/npm/img-comparison-slider@8/dist/index.js"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            "HTML-CSS": {
              scale: 95,
              fonts: ["Gyre-Pagella"],
              imageFont: null,
              undefinedFamily: "'Arial Unicode MS', cmbright"
            },
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                processEscapes: true
              }
          });
    </script>
    <script type="text/javascript"
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
</head>

<body>
    <!-- Title Page -->
    <!-- Dark Theme Example -->
    <!-- <div class="container blog" id="first-content" style="background-color: #304463;">
        <div class="blog-title white"> -->
    <div class="container blog" id="first-content" style="background-color: #E0E4E6;">
        <div class="blog-title">
            <div class="blog-intro">
                <div>
                    <h1 class="title">CochStream: Representing Speech Through Autoregressive Prediction of Cochlear Tokens</h1>
                    <p class="author">
                        Anonymous Sumbission
                    </p>
                    <p class="abstract">
                        We introduce a biologically-inspired model for encoding speech through an autoregressive prediction objective applied to input representations modeled after the human cochlea. Our modeling framework is inspired by the human auditory processing hierarchy. The first stage of our framework transforms the raw audio waveform to a time-frequency representation inspired by the human cochlea, with an intermediary step that effectively discretizes the audio representations (cochlear tokens). The second stage of our model learns a simple, yet powerful, autoregressive sequence model over the discretized audio input. We demonstrate that our model learns meaningful representations of phonemes and word identities, and state-of-the-art representations of lexical semantic similarity. In addition, our model shows competitive performance on several downstream audio tasks from the SUPERB benchmark. In addition to our model’s strong representational capabilities, we demonstrate our model's ability to generate continuations of audio at various temporal scales, which can be visualized in a cochleagram time-frequency space to provide insights into the model's predictions. Our model provides a novel framework for speech representation learning, aiming to advance the development of more human-like models that flexibly and efficiently handles a range of speech-based tasks.
                    </p>
                    <!-- Using FontAwesome Pro -->
                    <!-- <div>
                        <a href="https://arxiv.org" class="button icon" style="background-color: rgba(255, 255, 255, 0.3)"> Paper <i class="far fa-book-open"></i></a> &nbsp;&nbsp; 
                        <a href="https://github.com" class="button icon" style="background-color: rgba(255, 255, 255, 0.3)">Code <i class="far fa-code"></i></a>  &nbsp;&nbsp; 
                        <a href="https://www.microsoft.com/en-gb/microsoft-365/powerpoint" class="button icon" style="background-color: rgba(255, 255, 255, 0.3);">Slides <i class="far fa-presentation"></i></a>  &nbsp;&nbsp; 
                        <a href="https://huggingface.co/spaces" class="button icon" style="background-color: rgba(255, 255, 255, 0.3)">Demo <i class="fa-light fa-face-smiling-hands"></i></a>
                    </div> -->

                    <!-- Using FontAwesome Free -->
                    <!-- <div>
                        <a href="https://arxiv.org" class="button icon" style="background-color: rgba(255, 255, 255, 0.2)"> Paper <i class="fa-solid fa-book-open"></i></a> &nbsp;&nbsp; 
                        <a href="https://huggingface.co/datasets" class="button icon" style="background-color: rgba(255, 255, 255, 0.2)">Dataset <i class="fa-solid fa-database"></i></a>&nbsp;&nbsp; 
                        <a href="https://github.com" class="button icon" style="background-color: rgba(255, 255, 255, 0.2)">Code <i class="fa-solid fa-code"></i></a>  &nbsp;&nbsp; 
                        <a href="https://huggingface.co/spaces/" class="button icon" style="background-color: rgba(255, 255, 255, 0.2)">Demo <i class="fa-solid fa-laptop-code"></i></a> 
                    </div> -->
                </div>
               
            </div>

            <div class="blog-cover">
                <img class="foreground" src="assets/figures/logo.png">
                <img class="background" src="assets/figures/logo.png">

            </div>
        </div>
    </div>


    <div class="container blog main first" id="blog-main">
        <h1 >
            Additional Rollouts
        </h1>
        <p class='text'>
            We provide additional rollouts generated by our model - CochStream to showcase its diverse generation capabilities. We visualize generations under various seeds for several samples from the TIMIT dataset, which are not present in the training data. 
        </p>

        <h3>
            FCAU0 - SX137
        </h3>
        <img src="assets/figures/extra-rollout-1.png">

        <h3>
            MKJL0 - SX380
        </h3>
        <img src="assets/figures/extra-rollout-2.png">

        <h3>
            MGRT0 - SA1
        </h3>
        <img src="assets/figures/extra-rollout-3.png">

        <h3>
            FTLH0 - SX379
        </h3>
        <img src="assets/figures/extra-rollout-4.png">

    </div>


    <div class="container blog main first" id="blog-main" style="background-color: #E0E4E6;">
        <h1 >
            Rebuttal Figures
        </h1>
        <p class='text'>
            We provide additional figures to address the reviewer comments.
        </p>

        <h3>
        Figure 1
        </h3>
        <img src="assets/figures/architecture.png">
        <br>
        <p>
            <b>A. WavCoch Quantizer Architecture:</b> First, the raw waveform (shape: [1,80000] for 5s of mono audio sampled at 16kHz) undergoes the Fourier Transform by computing Twiddle Factors <a href="https://www.semanticscholar.org/paper/An-algorithm-for-the-machine-calculation-of-complex-Cooley-Tukey/0e6beb95b5150ce99b108acdefabf70ccd3fee30">[1]</a>. These factors represent complex sinusoidal components that decompose the signal into its frequency spectrum. The Twiddle Factors are applied to the audio signal through a 1D convolution (window size 1,001 and hop length 80 samples) which transforms the signal into the time-frequency domain. 
            Second, each 5 ms temporal step of this time-frequency representation is fed into two fully-connected (FC) layers with ReLU nonlinearities (with 512 hidden units each).
            Third, these embeddings are then passed through a 14-dimensional LFQ bottleneck <a href="https://arxiv.org/abs/2310.05737">[3]</a>, which effectively binarizes the representation. We read out the activations of this bottleneck as a 14-bit binary code which can be interpreted as one of 2^14 = 16,384 discrete tokens.
            Fourth, the output of the LFQ bottleneck is then projected to a 211 dimensional output, through two 1-dimensional convolutional layers (kernel size 10 and stride 1), separated by ReLU nonlinearities. This output corresponds to the frequencies in the cochleagram representation <a href="https://pubmed.ncbi.nlm.nih.gov/37845543/">[2]</a> which it is supervised to match via L2 error.
            Thus for every 5 seconds of audio, WavCoch extracts a sequence of 988 integers in the range [0, 16384) through the LFQ bottleneck, denoted as \textbf{cochlear tokens}, to feed into CochStream.
            <br>
            <b>B. CochStream Autoregressive Model Architecture:</b> The cochlear tokens obtained in WavCoch are passed to a GPT-style autoregressive Transformer <a href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf">[4]</a>, denoted as CochStream. We train two versions: CochStream-base (97M parameters), with 12 layers, 12 attention heads and an embedding size of 784 and CochStream-large (1.3B parameters) with 24 layers, 16 attention heads, and an embedding size of 2,048. Both models have a vocabulary size of 16,384. The CochStream model takes as input the cochlear token sequence produced by WavCoch and predicts the next token in the sequence. The context length is approximately 20s (4,096 tokens).  We utilize a learned positional embedding and compute the cross-entropy loss between the predicted logits and the true next token in the sequence.
        
        <h3>
        Figure 2
        </h3>
        <img src="assets/figures/WavCoch-cluster-purity-TIMIT.png">
        <br>
        <p>
            The plot investigates the vocabulary utilization rate in relation to the phoneme purity of each token. For each token, we define the purity as:
            Purity = (Count of most associated phoneme for token i) / (total counts for token i)
            Hence, the purity (on Figure 2’s y-axis) shows the purity for each cochlear token, whereas the color shows how many times a given token appears in the test set.
        </p>

        <h3>
        Figure 3
        </h3>
        <img src="assets/figures/waccoch_vocab_sizeplot.png">
        <br>
        <p>
            We train variants of WavCoch using a vocabulary size of 16384, 8192 and 4096 
            (14, 13 and 12 bit codes respectively) and report the reconstruction MSE and cluster
            purity for each on the out of distribution TIMIT test set. The experiments 
            indicate that a slightly smaller vocabulary size of 8192 is best for out of distrution generalization.
        </p>

        <h3>
        Figure 4
        </h3>
        <img src="assets/figures/QC3-librispeech960-8encstride38decstride9-aux001-vocab8192_model_best_heatmap.png">
        <br>
        <p>
            We plot the cluster purity of the best version of WavCoch according to our ablation experiments. 
            We find that multiple tokens are typically associated with each phoneme, and many of them are exclusively associated with a single phoenem. 
            Notably, a large number of tokens are linked to the "sil" (silence) label, but we would like to clarify that this label includes any non-speech sound, not true silence.
        </p>
    </div>


    <div class="container blog main first" id="blog-main">
        <h1 >
            
        </h1>
        <p class='text'>
            We provide additional rollouts generated by our model - CochStream to showcase its diverse generation capabilities. We visualize generations under various seeds for several samples from the LibriSpeech test set and TIMIT test set, which are not present in the training data. We then invert the cochleagrams back to audio and generate a video of a speech continuation from a given conditioning sequence. We would like to emphasize that these are not cherry picked, but rather the first random generations we created, under a consecutive series of random generator seeds.
        </p>

        <h3>
            LibriSpeech test - 4077-13754-0013
        </h3>
        <video controls>
            <source src="assets/figures/videos/auristream1B_librilight_model_00410000_4077-13754-0013_flac_rolloutsteps-494_rand-1110_20241127-134446.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="assets/figures/videos/auristream1B_librilight_model_00410000_4077-13754-0013_flac_rolloutsteps-494_rand-1110_20241127-134446_0.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="assets/figures/videos/auristream1B_librilight_model_00410000_4077-13754-0013_flac_rolloutsteps-494_rand-1110_20241127-134446_1.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="assets/figures/videos/auristream1B_librilight_model_00410000_4077-13754-0013_flac_rolloutsteps-494_rand-1110_20241127-134446_2.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="assets/figures/videos/auristream1B_librilight_model_00410000_4077-13754-0013_flac_rolloutsteps-494_rand-1110_20241127-134446_3.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="assets/figures/videos/auristream1B_librilight_model_00410000_4077-13754-0013_flac_rolloutsteps-494_rand-1110_20241127-134446_4.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>

        <br><br><br>

        <h3>
            LibriSpeech test - 237-126133-0000
        </h3>
        <video controls>
            <source src="assets/figures/videos/auristream1B_librilight_model_00410000_237-126133-0000_flac_rolloutsteps-494_rand-1110_20241127-141408.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="assets/figures/videos/auristream1B_librilight_model_00410000_237-126133-0000_flac_rolloutsteps-494_rand-1110_20241127-141408_0.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="assets/figures/videos/auristream1B_librilight_model_00410000_237-126133-0000_flac_rolloutsteps-494_rand-1110_20241127-141408_1.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="assets/figures/videos/auristream1B_librilight_model_00410000_237-126133-0000_flac_rolloutsteps-494_rand-1110_20241127-141408_2.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="assets/figures/videos/auristream1B_librilight_model_00410000_237-126133-0000_flac_rolloutsteps-494_rand-1110_20241127-141408_3.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="assets/figures/videos/auristream1B_librilight_model_00410000_237-126133-0000_flac_rolloutsteps-494_rand-1110_20241127-141408_4.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>

        <br><br><br>

        <h3>
            LibriSpeech test - 237-126133-0000
        </h3>
        <video controls>
            <source src="assets/figures/videos/auristream1B_librilight_model_00410000_237-126133-0000_flac_rolloutsteps-494_rand-1110_20241127-141408.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="assets/figures/videos/auristream1B_librilight_model_00410000_237-126133-0000_flac_rolloutsteps-494_rand-1110_20241127-141408_0.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="assets/figures/videos/auristream1B_librilight_model_00410000_237-126133-0000_flac_rolloutsteps-494_rand-1110_20241127-141408_1.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="assets/figures/videos/auristream1B_librilight_model_00410000_237-126133-0000_flac_rolloutsteps-494_rand-1110_20241127-141408_2.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="assets/figures/videos/auristream1B_librilight_model_00410000_237-126133-0000_flac_rolloutsteps-494_rand-1110_20241127-141408_3.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="assets/figures/videos/auristream1B_librilight_model_00410000_237-126133-0000_flac_rolloutsteps-494_rand-1110_20241127-141408_4.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>

        <br><br><br>

        <h3>
            TIMIT - SA1
        </h3>
        <video controls>
            <source src="assets/figures/videos/auristream1B_librilight_model_00410000_SA1_WAV_rolloutsteps-494_rand-1110_20241127-025058.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="assets/figures/videos/auristream1B_librilight_model_00410000_SA1_WAV_rolloutsteps-494_rand-1110_20241127-025058_0.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="assets/figures/videos/auristream1B_librilight_model_00410000_SA1_WAV_rolloutsteps-494_rand-1110_20241127-025058_1.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="assets/figures/videos/auristream1B_librilight_model_00410000_SA1_WAV_rolloutsteps-494_rand-1110_20241127-025058_2.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="assets/figures/videos/auristream1B_librilight_model_00410000_SA1_WAV_rolloutsteps-494_rand-1110_20241127-025058_3.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="assets/figures/videos/auristream1B_librilight_model_00410000_SA1_WAV_rolloutsteps-494_rand-1110_20241127-025058_4.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>

        <br><br><br>

        <h3>
            TIMIT - SX385
        </h3>
        <video controls>
            <source src="assets/figures/videos/auristream1B_librilight_model_00410000_SX385_WAV_rolloutsteps-494_rand-1110_20241127-124605.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="assets/figures/videos/auristream1B_librilight_model_00410000_SX385_WAV_rolloutsteps-494_rand-1110_20241127-124605_0.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="assets/figures/videos/auristream1B_librilight_model_00410000_SX385_WAV_rolloutsteps-494_rand-1110_20241127-124605_1.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="assets/figures/videos/auristream1B_librilight_model_00410000_SX385_WAV_rolloutsteps-494_rand-1110_20241127-124605_2.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="assets/figures/videos/auristream1B_librilight_model_00410000_SX385_WAV_rolloutsteps-494_rand-1110_20241127-124605_3.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <video controls>
            <source src="assets/figures/videos/auristream1B_librilight_model_00410000_SX385_WAV_rolloutsteps-494_rand-1110_20241127-124605_4.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
    </div>

    <div class="container blog main first" id="blog-main" style="background-color: #E0E4E6;">
        <h1 >
            Paper And Supplementary Revisions November 28, 2024
        </h1>
        <a href="assets/files/11854.pdf">Paper</a>
        <a href="assets/files/11854-supp.zip">Supplementary</a>

    </div>
    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script src="clarity/clarity.js"></script>    
    <script src="assets/scripts/main.js"></script>    
    </html>
</body>
